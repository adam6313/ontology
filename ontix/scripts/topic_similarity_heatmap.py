#!/usr/bin/env python3
"""
ç”¢ç”Ÿ 19 ä¸»é¡Œçš„ç›¸ä¼¼åº¦çŸ©é™£ç†±åŠ›åœ–
"""

import numpy as np
import psycopg2
from psycopg2.extras import RealDictCursor
import matplotlib.pyplot as plt
import matplotlib
matplotlib.use('Agg')  # ä½¿ç”¨éäº’å‹•å¼å¾Œç«¯
import matplotlib.font_manager as fm

# å˜—è©¦ä½¿ç”¨ç³»çµ±ä¸­æ–‡å­—é«”
chinese_fonts = [
    '/System/Library/Fonts/PingFang.ttc',
    '/System/Library/Fonts/STHeiti Light.ttc',
    '/Library/Fonts/Arial Unicode.ttf',
]
for font_path in chinese_fonts:
    import os
    if os.path.exists(font_path):
        fm.fontManager.addfont(font_path)
        matplotlib.rcParams['font.family'] = fm.FontProperties(fname=font_path).get_name()
        break
else:
    matplotlib.rcParams['font.family'] = ['Arial Unicode MS', 'Heiti TC', 'sans-serif']

matplotlib.rcParams['axes.unicode_minus'] = False
import seaborn as sns
from sklearn.metrics.pairwise import cosine_similarity
import json

# è³‡æ–™åº«é€£ç·š
conn = psycopg2.connect(
    host="localhost",
    port=5432,
    dbname="ontix_dev",
    user="ontix",
    password="ontix_dev"
)

def fetch_topics():
    """å–å¾—æ‰€æœ‰ä¸»é¡ŒåŠå…¶ embedding"""
    with conn.cursor(cursor_factory=RealDictCursor) as cur:
        cur.execute("""
            SELECT id, code, name, embedding
            FROM topics
            WHERE is_active = true AND embedding IS NOT NULL
            ORDER BY post_count DESC, id
        """)
        return cur.fetchall()

def parse_embedding(emb_str):
    """è§£æ pgvector æ ¼å¼çš„ embedding"""
    if emb_str is None:
        return None
    if isinstance(emb_str, list):
        return np.array(emb_str)
    # pgvector æ ¼å¼: [0.1,0.2,0.3,...]
    clean = emb_str.strip('[]')
    return np.array([float(x) for x in clean.split(',')])

def main():
    print("ğŸ“Š å–å¾—ä¸»é¡Œè³‡æ–™...")
    topics = fetch_topics()
    print(f"   æ‰¾åˆ° {len(topics)} å€‹ä¸»é¡Œ")

    # è§£æ embeddings
    names = []
    embeddings = []

    for t in topics:
        emb = parse_embedding(t['embedding'])
        if emb is not None and len(emb) > 0:
            names.append(t['name'])
            embeddings.append(emb)
            print(f"   âœ“ {t['name']} ({t['code']})")

    if len(embeddings) < 2:
        print("âŒ éœ€è¦è‡³å°‘ 2 å€‹æœ‰ embedding çš„ä¸»é¡Œ")
        return

    # è½‰æ›ç‚ºçŸ©é™£
    emb_matrix = np.vstack(embeddings)
    print(f"\nğŸ“ Embedding çŸ©é™£å½¢ç‹€: {emb_matrix.shape}")

    # è¨ˆç®—ç›¸ä¼¼åº¦çŸ©é™£
    print("\nğŸ”¢ è¨ˆç®— Cosine Similarity...")
    sim_matrix = cosine_similarity(emb_matrix)

    # æ‰¾å‡ºé«˜ç›¸ä¼¼åº¦çš„ä¸»é¡Œå° (é™ä½é–¾å€¼åˆ° 0.40 å› ç‚ºæ•´é«”ç›¸ä¼¼åº¦è¼ƒä½)
    print("\nğŸ” ç›¸å°é«˜ç›¸ä¼¼åº¦ä¸»é¡Œå° (similarity > 0.40):")
    print("-" * 60)

    high_sim_pairs = []
    for i in range(len(names)):
        for j in range(i + 1, len(names)):
            sim = sim_matrix[i][j]
            if sim > 0.40:
                high_sim_pairs.append((names[i], names[j], sim))
                print(f"   {names[i]} â†” {names[j]}: {sim:.4f}")

    if not high_sim_pairs:
        print("   (ç„¡)")

    # çµ±è¨ˆ
    upper_tri = sim_matrix[np.triu_indices(len(names), k=1)]
    print(f"\nğŸ“ˆ ç›¸ä¼¼åº¦çµ±è¨ˆ:")
    print(f"   å¹³å‡: {upper_tri.mean():.4f}")
    print(f"   æ¨™æº–å·®: {upper_tri.std():.4f}")
    print(f"   æœ€é«˜: {upper_tri.max():.4f}")
    print(f"   æœ€ä½: {upper_tri.min():.4f}")

    # ç¹ªè£½ç†±åŠ›åœ–
    print("\nğŸ¨ ç¹ªè£½ç†±åŠ›åœ–...")

    plt.figure(figsize=(14, 12))

    # ä½¿ç”¨ seaborn ç†±åŠ›åœ–
    mask = np.zeros_like(sim_matrix)
    # np.fill_diagonal(mask, True)  # å¯é¸ï¼šéš±è—å°è§’ç·š

    sns.heatmap(
        sim_matrix,
        xticklabels=names,
        yticklabels=names,
        annot=True,
        fmt='.2f',
        cmap='RdYlGn_r',  # ç´…(é«˜ç›¸ä¼¼)â†’é»ƒâ†’ç¶ (ä½ç›¸ä¼¼)
        vmin=0.15,
        vmax=0.55,
        center=0.35,
        square=True,
        linewidths=0.5,
        cbar_kws={'label': 'Cosine Similarity'}
    )

    plt.title('19 Topic Embedding Similarity Matrix\n(Topics are well-separated - max similarity only 0.51)', fontsize=14, fontweight='bold')
    plt.xticks(rotation=45, ha='right', fontsize=10)
    plt.yticks(rotation=0, fontsize=10)
    plt.tight_layout()

    # å„²å­˜
    output_path = '/Users/adam/poc/ontology/ontix/scripts/topic_similarity_heatmap.png'
    plt.savefig(output_path, dpi=150, bbox_inches='tight')
    print(f"\nâœ… ç†±åŠ›åœ–å·²å„²å­˜: {output_path}")

    # ç”¢ç”Ÿå»ºè­°
    print("\n" + "=" * 60)
    print("ğŸ“‹ åˆ†æå»ºè­°")
    print("=" * 60)

    if high_sim_pairs:
        print(f"\nâš ï¸  ç™¼ç¾ {len(high_sim_pairs)} å°ç›¸å°é«˜ç›¸ä¼¼åº¦ä¸»é¡Œ (>0.40):")
        for t1, t2, sim in sorted(high_sim_pairs, key=lambda x: -x[2]):
            print(f"   â€¢ {t1} + {t2} ({sim:.2f})")

    # æ‰¾å‡ºèˆ‡å¤šå€‹ä¸»é¡Œéƒ½é«˜åº¦ç›¸ä¼¼çš„
    high_sim_count = {}
    for t1, t2, sim in high_sim_pairs:
        high_sim_count[t1] = high_sim_count.get(t1, 0) + 1
        high_sim_count[t2] = high_sim_count.get(t2, 0) + 1

    multi_overlap = [(t, c) for t, c in high_sim_count.items() if c >= 2]
    if multi_overlap:
        print(f"\nğŸ¯ èˆ‡å¤šå€‹ä¸»é¡Œé‡ç–Šçš„ã€Œæ©‹æ¥ä¸»é¡Œã€:")
        for t, c in sorted(multi_overlap, key=lambda x: -x[1]):
            print(f"   â€¢ {t} - èˆ‡ {c} å€‹ä¸»é¡Œç›¸å°é«˜ç›¸ä¼¼")

    # é‡è¦ç™¼ç¾
    print("\n" + "=" * 60)
    print("ğŸ”¬ é—œéµç™¼ç¾")
    print("=" * 60)
    print(f"""
    ä¸»é¡Œé–“å¹³å‡ç›¸ä¼¼åº¦åªæœ‰ {upper_tri.mean():.2f}ï¼Œæœ€é«˜ä¹Ÿåªæœ‰ {upper_tri.max():.2f}

    é€™èªªæ˜ï¼š19 å€‹ä¸»é¡Œçš„ embedding å®šç¾©å…¶å¯¦åˆ†å¾—å¾ˆé–‹ï¼

    25% çš„æ¨¡ç³Šåˆ†é¡ä¸æ˜¯å› ç‚ºã€Œä¸»é¡Œå¤ªç›¸ä¼¼ã€ï¼Œè€Œæ˜¯å› ç‚ºï¼š
    1. è²¼æ–‡å…§å®¹æœ¬èº«æ¶µè“‹å¤šå€‹ä¸»é¡Œï¼ˆçœŸå¯¦çš„å¤šæ¨™ç±¤æƒ…æ³ï¼‰
    2. è²¼æ–‡å…§å®¹éæ–¼æ¨¡ç³Š/çŸ­/ç¼ºä¹ç‰¹å¾µ
    3. æŸäº›è²¼æ–‡æ ¹æœ¬ä¸å±¬æ–¼ä»»ä½•é å®šç¾©ä¸»é¡Œ

    å»ºè­°ï¼š
    â€¢ ä¸éœ€è¦åˆä½µä¸»é¡Œ
    â€¢ æ‡‰è©²å…è¨±å¤šæ¨™ç±¤åˆ†é¡
    â€¢ å°æ–¼ã€Œå“ªå€‹éƒ½ä¸åƒã€çš„è²¼æ–‡ï¼Œè€ƒæ…®æ–°å¢ã€Œå…¶ä»–/é›œè«‡ã€é¡åˆ¥
    """)

    # è¼¸å‡º JSON ä¾›é€²ä¸€æ­¥åˆ†æ
    json_output = {
        'topics': names,
        'similarity_matrix': sim_matrix.tolist(),
        'high_similarity_pairs': [(t1, t2, float(sim)) for t1, t2, sim in high_sim_pairs],
        'statistics': {
            'mean': float(upper_tri.mean()),
            'std': float(upper_tri.std()),
            'max': float(upper_tri.max()),
            'min': float(upper_tri.min())
        }
    }

    json_path = '/Users/adam/poc/ontology/ontix/scripts/topic_similarity.json'
    with open(json_path, 'w', encoding='utf-8') as f:
        json.dump(json_output, f, ensure_ascii=False, indent=2)
    print(f"\nğŸ“„ JSON è³‡æ–™å·²å„²å­˜: {json_path}")

if __name__ == '__main__':
    main()
