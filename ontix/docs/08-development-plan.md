# é–‹ç™¼è¨ˆåŠƒæ–‡ä»¶
## Dynamic Tagging System PoC

**ç‰ˆæœ¬**ï¼šv1.0
**æ—¥æœŸ**ï¼š2026-02-03
**ä½œè€…**ï¼šKolr Engineering Team
**é—œè¯ PRD**ï¼š[07-dynamic-tagging-prd.md](./07-dynamic-tagging-prd.md)

---

## 1. ç¸½è¦½

### 1.1 ç›®æ¨™

åœ¨ 2 é€±å…§å®Œæˆ Dynamic Tagging System PoCï¼Œè™•ç† 5 è¬ç¯‡ç¾å¦è²¼æ–‡ï¼Œé©—è­‰ï¼š
- æ¨™ç±¤ç›¸é—œæ€§ â‰¥ 85%
- è¦†è“‹ç‡ â‰¥ 90%
- èšé¡ä¸€è‡´æ€§ â‰¥ 80%

### 1.2 æŠ€è¡“æ£§

| å±¤ç´š | æŠ€è¡“ | ç”¨é€” |
|------|------|------|
| **ä¸»æœå‹™** | Go 1.21+ | æµç¨‹æ§åˆ¶ã€API |
| **ML æœå‹™** | Python 3.10+ | Embeddingã€HDBSCAN |
| **é€šè¨Š** | gRPC | Go â†” Python |
| **å‘é‡ DB** | Qdrant | èªæ„æœå°‹ |
| **å¿«å–** | Redis | Centroid å„²å­˜ |
| **é—œè¯ DB** | PostgreSQL | æ¨™ç±¤å„²å­˜ |
| **LLM** | GPT-4o-mini | Soft Tagging |
| **Embedding** | MiniLM-L12-v2 | 384 ç¶­å‘é‡ |
| **Clustering** | HDBSCAN | ä¸»é¡Œç™¼ç¾ |

### 1.3 æ™‚ç¨‹ç¸½è¦½

```
Week 1                              Week 2
Day 1-2    Day 3-7                  Day 8-10     Day 11-14
â”‚          â”‚                        â”‚            â”‚
â–¼          â–¼                        â–¼            â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Phase 0â”‚ â”‚      Phase 1         â”‚ â”‚ Phase 2  â”‚ â”‚ Phase 3  â”‚
â”‚  ç’°å¢ƒ  â”‚ â”‚     æ ¸å¿ƒå…ƒä»¶         â”‚ â”‚ æµç¨‹æ•´åˆ â”‚ â”‚ API+é©—è­‰ â”‚
â”‚  æº–å‚™  â”‚ â”‚                      â”‚ â”‚          â”‚ â”‚          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 2. Phase 0: ç’°å¢ƒæº–å‚™ (Day 1-2)

### 2.1 Docker Compose ç’°å¢ƒ

```yaml
# docker-compose.yml
version: '3.8'

services:
  redis:
    image: redis:7-alpine
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data

  qdrant:
    image: qdrant/qdrant:latest
    ports:
      - "6333:6333"
      - "6334:6334"
    volumes:
      - qdrant_data:/qdrant/storage

  postgres:
    image: postgres:15-alpine
    ports:
      - "5432:5432"
    environment:
      POSTGRES_DB: kolr_tagging
      POSTGRES_USER: kolr
      POSTGRES_PASSWORD: kolr_dev
    volumes:
      - postgres_data:/var/lib/postgresql/data

  ml-service:
    build: ./ml_service
    ports:
      - "50051:50051"
    volumes:
      - ./ml_service:/app
      - model_cache:/root/.cache

volumes:
  redis_data:
  qdrant_data:
  postgres_data:
  model_cache:
```

### 2.2 Python ML ç’°å¢ƒ

```txt
# ml_service/requirements.txt
sentence-transformers==2.2.2
hdbscan==0.8.33
numpy==1.24.3
grpcio==1.59.0
grpcio-tools==1.59.0
openai==1.3.0
scikit-learn==1.3.2
```

### 2.3 Go ä¾è³´

```go
// go.mod
module kolr-dynamic-tagging

go 1.21

require (
    github.com/redis/go-redis/v9 v9.3.0
    github.com/qdrant/go-client v1.7.0
    github.com/lib/pq v1.10.9
    github.com/sashabaranov/go-openai v1.17.9
    google.golang.org/grpc v1.59.0
    google.golang.org/protobuf v1.31.0
)
```

### 2.4 æ¸¬è©¦è³‡æ–™æº–å‚™

```sql
-- scripts/export_posts.sql
COPY (
    SELECT
        id,
        content,
        likes,
        comments,
        platform,
        author_id,
        created_at
    FROM posts
    WHERE category = 'ç¾å¦'
      AND created_at >= '2024-01-01'
      AND LENGTH(content) >= 20
    ORDER BY created_at DESC
    LIMIT 50000
) TO '/tmp/beauty_posts_50k.json' WITH (FORMAT JSON);
```

### 2.5 è³‡æ–™åº« Schema

```sql
-- scripts/init.sql

-- è²¼æ–‡æ¨™ç±¤è¡¨
CREATE TABLE post_tags (
    id SERIAL PRIMARY KEY,
    post_id VARCHAR(50) NOT NULL UNIQUE,
    hard_tags JSONB DEFAULT '[]',
    soft_tags JSONB DEFAULT '[]',
    sentiment VARCHAR(20),
    cluster_id VARCHAR(50),
    risk_score INT,
    created_at TIMESTAMP DEFAULT NOW(),
    updated_at TIMESTAMP DEFAULT NOW()
);

CREATE INDEX idx_post_tags_cluster ON post_tags(cluster_id);
CREATE INDEX idx_post_tags_sentiment ON post_tags(sentiment);

-- Cluster è³‡è¨Šè¡¨
CREATE TABLE clusters (
    id VARCHAR(50) PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    keywords JSONB DEFAULT '[]',
    post_count INT DEFAULT 0,
    status VARCHAR(20) DEFAULT 'EMERGING',
    parent_hard_tag VARCHAR(50),
    created_at TIMESTAMP DEFAULT NOW(),
    updated_at TIMESTAMP DEFAULT NOW()
);

-- Cluster æ­·å²è¨˜éŒ„
CREATE TABLE cluster_history (
    id SERIAL PRIMARY KEY,
    cluster_id VARCHAR(50) NOT NULL,
    event_type VARCHAR(20) NOT NULL,
    event_data JSONB,
    created_at TIMESTAMP DEFAULT NOW()
);
```

### 2.6 Phase 0 Checklist

```
â˜ Docker Compose å•Ÿå‹•æˆåŠŸ
  â˜ Redis é€£ç·šæ¸¬è©¦
  â˜ Qdrant é€£ç·šæ¸¬è©¦
  â˜ PostgreSQL é€£ç·šæ¸¬è©¦

â˜ Python ç’°å¢ƒ
  â˜ requirements.txt å®‰è£å®Œæˆ
  â˜ MiniLM æ¨¡å‹ä¸‹è¼‰å®Œæˆ (é¦–æ¬¡ç´„ 500MB)

â˜ Go ç’°å¢ƒ
  â˜ go mod tidy å®Œæˆ
  â˜ protoc ç·¨è­¯ gRPC

â˜ æ¸¬è©¦è³‡æ–™
  â˜ åŒ¯å‡º 50,000 ç¯‡è²¼æ–‡
  â˜ é©—è­‰ JSON æ ¼å¼æ­£ç¢º
```

---

## 3. Phase 1: æ ¸å¿ƒå…ƒä»¶é–‹ç™¼ (Day 3-7)

### 3.1 Step 1: Embedding Service (Day 3)

**æª”æ¡ˆ**: `ml_service/embedding_server.py`

```python
# proto/ml.proto
syntax = "proto3";

package ml;

service EmbeddingService {
    rpc Embed(EmbedRequest) returns (EmbedResponse);
    rpc BatchEmbed(BatchEmbedRequest) returns (BatchEmbedResponse);
}

message EmbedRequest {
    string text = 1;
}

message EmbedResponse {
    repeated float embedding = 1;
}

message BatchEmbedRequest {
    repeated string texts = 1;
}

message BatchEmbedResponse {
    repeated Embedding embeddings = 1;
}

message Embedding {
    repeated float values = 1;
}
```

```python
# ml_service/embedding_server.py
import grpc
from concurrent import futures
from sentence_transformers import SentenceTransformer
import ml_pb2
import ml_pb2_grpc

class EmbeddingService(ml_pb2_grpc.EmbeddingServiceServicer):
    def __init__(self):
        print("Loading MiniLM model...")
        self.model = SentenceTransformer('paraphrase-multilingual-MiniLM-L12-v2')
        print("Model loaded!")

    def Embed(self, request, context):
        embedding = self.model.encode(request.text)
        return ml_pb2.EmbedResponse(embedding=embedding.tolist())

    def BatchEmbed(self, request, context):
        texts = list(request.texts)
        embeddings = self.model.encode(texts)

        response = ml_pb2.BatchEmbedResponse()
        for emb in embeddings:
            response.embeddings.append(
                ml_pb2.Embedding(values=emb.tolist())
            )
        return response

def serve():
    server = grpc.server(futures.ThreadPoolExecutor(max_workers=4))
    ml_pb2_grpc.add_EmbeddingServiceServicer_to_server(
        EmbeddingService(), server
    )
    server.add_insecure_port('[::]:50051')
    print("Embedding service started on port 50051")
    server.start()
    server.wait_for_termination()

if __name__ == '__main__':
    serve()
```

**é©—æ”¶æ¨™æº–**:
```
â˜ gRPC æœå‹™å•Ÿå‹•æˆåŠŸ
â˜ å–®ç¯‡ Embed: "é€™å€‹æ°£å¢Šè¶…æŒå¦" â†’ 384 ç¶­å‘é‡
â˜ æ‰¹æ¬¡ 100 ç¯‡ < 2 ç§’
â˜ å‘é‡ L2 norm â‰ˆ 1.0
```

---

### 3.2 Step 2: Centroid Manager (Day 4)

**æª”æ¡ˆ**: `internal/clustering/centroid_manager.go`

```go
package clustering

import (
    "context"
    "encoding/json"
    "math"

    "github.com/redis/go-redis/v9"
)

type CentroidManager struct {
    redis     *redis.Client
    threshold float64
}

func NewCentroidManager(redisClient *redis.Client, threshold float64) *CentroidManager {
    return &CentroidManager{
        redis:     redisClient,
        threshold: threshold,
    }
}

// FindNearest æ‰¾æœ€ç›¸ä¼¼çš„ Cluster
func (cm *CentroidManager) FindNearest(ctx context.Context, embedding []float64) (string, float64, error) {
    centroids, err := cm.GetAll(ctx)
    if err != nil {
        return "", 0, err
    }

    if len(centroids) == 0 {
        return "", 0, nil // å†·å•Ÿå‹•ï¼Œæ²’æœ‰ Centroid
    }

    var bestID string
    var bestScore float64 = -1

    for id, centroid := range centroids {
        score := cosineSimilarity(embedding, centroid)
        if score > bestScore {
            bestScore = score
            bestID = id
        }
    }

    if bestScore >= cm.threshold {
        return bestID, bestScore, nil
    }

    return "", bestScore, nil // æ¯”å°å¤±æ•—
}

// GetAll å¾ Redis è¼‰å…¥æ‰€æœ‰ Centroid
func (cm *CentroidManager) GetAll(ctx context.Context) (map[string][]float64, error) {
    result, err := cm.redis.HGetAll(ctx, "cluster:centroids").Result()
    if err != nil {
        return nil, err
    }

    centroids := make(map[string][]float64)
    for id, data := range result {
        var vec []float64
        if err := json.Unmarshal([]byte(data), &vec); err != nil {
            continue
        }
        centroids[id] = vec
    }

    return centroids, nil
}

// Add æ–°å¢ Centroid
func (cm *CentroidManager) Add(ctx context.Context, clusterID string, centroid []float64) error {
    data, err := json.Marshal(centroid)
    if err != nil {
        return err
    }
    return cm.redis.HSet(ctx, "cluster:centroids", clusterID, data).Err()
}

// Update æ›´æ–° Centroid (å¢é‡å¹³å‡)
func (cm *CentroidManager) Update(ctx context.Context, clusterID string, newCentroid []float64) error {
    return cm.Add(ctx, clusterID, newCentroid)
}

// Delete åˆªé™¤ Centroid
func (cm *CentroidManager) Delete(ctx context.Context, clusterID string) error {
    return cm.redis.HDel(ctx, "cluster:centroids", clusterID).Err()
}

// Count å›å‚³ Centroid æ•¸é‡
func (cm *CentroidManager) Count(ctx context.Context) (int64, error) {
    return cm.redis.HLen(ctx, "cluster:centroids").Result()
}

func cosineSimilarity(a, b []float64) float64 {
    if len(a) != len(b) {
        return 0
    }

    var dot, normA, normB float64
    for i := range a {
        dot += a[i] * b[i]
        normA += a[i] * a[i]
        normB += b[i] * b[i]
    }

    if normA == 0 || normB == 0 {
        return 0
    }

    return dot / (math.Sqrt(normA) * math.Sqrt(normB))
}
```

**é©—æ”¶æ¨™æº–**:
```
â˜ Add 10 å€‹ Centroid æˆåŠŸ
â˜ FindNearest æ­£ç¢ºæ‰¾å‡ºæœ€ç›¸ä¼¼
â˜ æŸ¥è©¢å»¶é² < 1ms
â˜ Count å›å‚³æ­£ç¢ºæ•¸é‡
```

---

### 3.3 Step 3: HDBSCAN Service (Day 5)

**æª”æ¡ˆ**: `ml_service/clustering_server.py`

```python
# ml_service/clustering_server.py
import grpc
from concurrent import futures
import hdbscan
import numpy as np
from openai import OpenAI
import json

import ml_pb2
import ml_pb2_grpc

class ClusteringService(ml_pb2_grpc.ClusteringServiceServicer):
    def __init__(self):
        self.openai = OpenAI()

    def RunClustering(self, request, context):
        # 1. è½‰æ› embeddings
        embeddings = np.array([list(e.values) for e in request.embeddings])
        texts = list(request.texts)

        # 2. HDBSCAN èšé¡
        clusterer = hdbscan.HDBSCAN(
            min_cluster_size=request.min_cluster_size or 50,
            min_samples=10,
            metric='euclidean'
        )
        labels = clusterer.fit_predict(embeddings)

        # 3. è™•ç†æ¯å€‹ Cluster
        response = ml_pb2.ClusteringResponse()

        unique_labels = set(labels)
        for label in unique_labels:
            if label == -1:  # å™ªé»
                continue

            mask = labels == label
            cluster_embeddings = embeddings[mask]
            cluster_texts = [texts[i] for i in range(len(texts)) if mask[i]]

            # è¨ˆç®— Centroid
            centroid = cluster_embeddings.mean(axis=0)

            # LLM å‘½å
            name, keywords = self._generate_name(cluster_texts[:10])

            cluster = ml_pb2.Cluster(
                centroid=ml_pb2.Embedding(values=centroid.tolist()),
                size=int(mask.sum()),
                name=name,
                keywords=keywords
            )
            response.clusters.append(cluster)

        response.noise_count = int((labels == -1).sum())

        return response

    def _generate_name(self, sample_texts):
        prompt = f"""åˆ†æä»¥ä¸‹ç¤¾ç¾¤è²¼æ–‡ï¼Œå®ƒå€‘å±¬æ–¼åŒä¸€å€‹è¨è«–ä¸»é¡Œã€‚

è²¼æ–‡æ¨£æœ¬ï¼š
{chr(10).join(f'- {t[:150]}' for t in sample_texts[:5])}

è«‹æä¾›ï¼š
1. ä¸»é¡Œåç¨±ï¼ˆ2-4å€‹å­—ï¼‰
2. 3-5å€‹é—œéµè©

å›è¦† JSON æ ¼å¼ï¼š
{{"name": "...", "keywords": [...]}}"""

        response = self.openai.chat.completions.create(
            model="gpt-4o-mini",
            messages=[{"role": "user", "content": prompt}],
            response_format={"type": "json_object"},
            max_tokens=100
        )

        result = json.loads(response.choices[0].message.content)
        return result.get("name", "æœªå‘½å"), result.get("keywords", [])


def serve():
    server = grpc.server(futures.ThreadPoolExecutor(max_workers=2))
    ml_pb2_grpc.add_ClusteringServiceServicer_to_server(
        ClusteringService(), server
    )
    server.add_insecure_port('[::]:50052')
    print("Clustering service started on port 50052")
    server.start()
    server.wait_for_termination()

if __name__ == '__main__':
    serve()
```

**é©—æ”¶æ¨™æº–**:
```
â˜ è¼¸å…¥ 5000 å€‹ embedding â†’ è¼¸å‡º 15-25 å€‹ Cluster
â˜ æ¯å€‹ Cluster æœ‰ name + keywords
â˜ åŸ·è¡Œæ™‚é–“ < 15 ç§’
â˜ noise_count < 20%
```

---

### 3.4 Step 4: LLM Tagger (Day 6)

**æª”æ¡ˆ**: `internal/tagging/soft_tagger.go`

```go
package tagging

import (
    "context"
    "encoding/json"
    "fmt"

    "github.com/sashabaranov/go-openai"
)

type SoftTagger struct {
    client *openai.Client
}

type TagResult struct {
    SoftTags    []string `json:"soft_tags"`
    Sentiment   string   `json:"sentiment"`
    ProductType string   `json:"product_type,omitempty"`
}

func NewSoftTagger(apiKey string) *SoftTagger {
    return &SoftTagger{
        client: openai.NewClient(apiKey),
    }
}

func (st *SoftTagger) Tag(ctx context.Context, content string) (*TagResult, error) {
    prompt := fmt.Sprintf(`åˆ†æé€™ç¯‡ç¤¾ç¾¤è²¼æ–‡ï¼Œæå–æ¨™ç±¤è³‡è¨Šã€‚

è²¼æ–‡ï¼š%s

å›è¦† JSON æ ¼å¼ï¼š
{
  "soft_tags": ["æ¨™ç±¤1", "æ¨™ç±¤2", ...],
  "sentiment": "positive/negative/neutral",
  "product_type": "ç”¢å“é¡å‹ï¼ˆå¦‚æœ‰ï¼‰"
}`, content)

    resp, err := st.client.CreateChatCompletion(
        ctx,
        openai.ChatCompletionRequest{
            Model: openai.GPT4oMini,
            Messages: []openai.ChatCompletionMessage{
                {Role: openai.ChatMessageRoleUser, Content: prompt},
            },
            ResponseFormat: &openai.ChatCompletionResponseFormat{
                Type: openai.ChatCompletionResponseFormatTypeJSONObject,
            },
            MaxTokens: 150,
        },
    )
    if err != nil {
        return nil, err
    }

    var result TagResult
    if err := json.Unmarshal([]byte(resp.Choices[0].Message.Content), &result); err != nil {
        return nil, err
    }

    return &result, nil
}

func (st *SoftTagger) BatchTag(ctx context.Context, contents []string) ([]*TagResult, error) {
    results := make([]*TagResult, len(contents))

    for i, content := range contents {
        result, err := st.Tag(ctx, content)
        if err != nil {
            results[i] = &TagResult{Sentiment: "unknown"}
            continue
        }
        results[i] = result
    }

    return results, nil
}
```

**é©—æ”¶æ¨™æº–**:
```
â˜ è¼¸å…¥ "é€™å€‹æ°£å¢Šè¶…æŒå¦" â†’ soft_tags åŒ…å«ç›¸é—œæ¨™ç±¤
â˜ sentiment ç‚º positive/negative/neutral
â˜ å–®ç¯‡å»¶é² < 500ms
â˜ éŒ¯èª¤è™•ç†æ­£å¸¸
```

---

### 3.5 Step 5: Storage Layer (Day 7)

**æª”æ¡ˆ**: `internal/storage/qdrant.go`

```go
package storage

import (
    "context"

    "github.com/qdrant/go-client/qdrant"
)

type QdrantStore struct {
    client     *qdrant.Client
    collection string
}

func NewQdrantStore(host string, port int, collection string) (*QdrantStore, error) {
    client, err := qdrant.NewClient(&qdrant.Config{
        Host: host,
        Port: port,
    })
    if err != nil {
        return nil, err
    }

    return &QdrantStore{
        client:     client,
        collection: collection,
    }, nil
}

func (qs *QdrantStore) InitCollection(ctx context.Context, vectorSize uint64) error {
    return qs.client.CreateCollection(ctx, &qdrant.CreateCollection{
        CollectionName: qs.collection,
        VectorsConfig: qdrant.NewVectorsConfig(&qdrant.VectorParams{
            Size:     vectorSize,
            Distance: qdrant.Distance_Cosine,
        }),
    })
}

func (qs *QdrantStore) Upsert(ctx context.Context, id string, vector []float32, payload map[string]interface{}) error {
    points := []*qdrant.PointStruct{
        {
            Id:      qdrant.NewIDStr(id),
            Vectors: qdrant.NewVectors(vector...),
            Payload: qdrant.NewValueMap(payload),
        },
    }

    _, err := qs.client.Upsert(ctx, &qdrant.UpsertPoints{
        CollectionName: qs.collection,
        Points:         points,
    })
    return err
}

func (qs *QdrantStore) Search(ctx context.Context, vector []float32, limit uint64) ([]*qdrant.ScoredPoint, error) {
    result, err := qs.client.Query(ctx, &qdrant.QueryPoints{
        CollectionName: qs.collection,
        Query:          qdrant.NewQuery(vector...),
        Limit:          qdrant.PtrOf(limit),
        WithPayload:    qdrant.NewWithPayload(true),
    })
    if err != nil {
        return nil, err
    }
    return result, nil
}
```

**æª”æ¡ˆ**: `internal/storage/postgres.go`

```go
package storage

import (
    "context"
    "database/sql"
    "encoding/json"

    _ "github.com/lib/pq"
)

type PostgresStore struct {
    db *sql.DB
}

type PostTag struct {
    PostID    string   `json:"post_id"`
    HardTags  []string `json:"hard_tags"`
    SoftTags  []string `json:"soft_tags"`
    Sentiment string   `json:"sentiment"`
    ClusterID string   `json:"cluster_id"`
    RiskScore int      `json:"risk_score"`
}

func NewPostgresStore(connStr string) (*PostgresStore, error) {
    db, err := sql.Open("postgres", connStr)
    if err != nil {
        return nil, err
    }
    return &PostgresStore{db: db}, nil
}

func (ps *PostgresStore) SavePostTag(ctx context.Context, pt *PostTag) error {
    hardTagsJSON, _ := json.Marshal(pt.HardTags)
    softTagsJSON, _ := json.Marshal(pt.SoftTags)

    _, err := ps.db.ExecContext(ctx, `
        INSERT INTO post_tags (post_id, hard_tags, soft_tags, sentiment, cluster_id, risk_score)
        VALUES ($1, $2, $3, $4, $5, $6)
        ON CONFLICT (post_id) DO UPDATE SET
            hard_tags = $2,
            soft_tags = $3,
            sentiment = $4,
            cluster_id = $5,
            risk_score = $6,
            updated_at = NOW()
    `, pt.PostID, hardTagsJSON, softTagsJSON, pt.Sentiment, pt.ClusterID, pt.RiskScore)

    return err
}

func (ps *PostgresStore) GetPostsByCluster(ctx context.Context, clusterID string, limit int) ([]*PostTag, error) {
    rows, err := ps.db.QueryContext(ctx, `
        SELECT post_id, hard_tags, soft_tags, sentiment, cluster_id, risk_score
        FROM post_tags
        WHERE cluster_id = $1
        LIMIT $2
    `, clusterID, limit)
    if err != nil {
        return nil, err
    }
    defer rows.Close()

    var results []*PostTag
    for rows.Next() {
        var pt PostTag
        var hardTagsJSON, softTagsJSON []byte

        if err := rows.Scan(&pt.PostID, &hardTagsJSON, &softTagsJSON, &pt.Sentiment, &pt.ClusterID, &pt.RiskScore); err != nil {
            continue
        }

        json.Unmarshal(hardTagsJSON, &pt.HardTags)
        json.Unmarshal(softTagsJSON, &pt.SoftTags)
        results = append(results, &pt)
    }

    return results, nil
}
```

**é©—æ”¶æ¨™æº–**:
```
â˜ Qdrant: å»ºç«‹ collection æˆåŠŸ
â˜ Qdrant: å¯«å…¥ 1000 ç­† < 5 ç§’
â˜ Qdrant: Search Top 10 < 50ms
â˜ PostgreSQL: SavePostTag æˆåŠŸ
â˜ PostgreSQL: GetPostsByCluster æˆåŠŸ
```

---

## 4. Phase 2: æµç¨‹æ•´åˆ (Day 8-10)

### 4.1 Step 6: Post Processor (Day 8-9)

**æª”æ¡ˆ**: `cmd/processor/main.go`

```go
package main

import (
    "context"
    "encoding/json"
    "fmt"
    "log"
    "os"
    "strings"

    "kolr-dynamic-tagging/internal/clustering"
    "kolr-dynamic-tagging/internal/ml"
    "kolr-dynamic-tagging/internal/storage"
    "kolr-dynamic-tagging/internal/tagging"
)

type Post struct {
    ID       string `json:"id"`
    Content  string `json:"content"`
    Likes    int    `json:"likes"`
    Comments int    `json:"comments"`
    Platform string `json:"platform"`
}

type Processor struct {
    embedClient     *ml.EmbeddingClient
    centroidMgr     *clustering.CentroidManager
    softTagger      *tagging.SoftTagger
    qdrantStore     *storage.QdrantStore
    postgresStore   *storage.PostgresStore
    pendingPool     *storage.RedisQueue
}

func (p *Processor) Process(ctx context.Context, post *Post) error {
    // Step 1: Rules Filter
    if !p.rulesFilter(post) {
        return nil // ä¸Ÿæ£„
    }

    // Step 2: Risk Score
    riskScore := p.calculateRiskScore(post)

    // Step 3: Embedding
    embedding, err := p.embedClient.Embed(ctx, post.Content)
    if err != nil {
        return fmt.Errorf("embedding failed: %w", err)
    }

    // Step 4: Centroid æ¯”å°
    clusterID, score, err := p.centroidMgr.FindNearest(ctx, embedding)
    if err != nil {
        return fmt.Errorf("centroid match failed: %w", err)
    }

    // Step 5: åˆ†æµè™•ç†
    if clusterID == "" {
        // æ¯”å°å¤±æ•—ï¼Œæ”¾å…¥ Pending Pool
        return p.pendingPool.Push(ctx, post.ID, embedding)
    }

    // Step 6: LLM Tagging (åƒ…é«˜åƒ¹å€¼è²¼æ–‡)
    var tagResult *tagging.TagResult
    if riskScore >= 70 {
        tagResult, _ = p.softTagger.Tag(ctx, post.Content)
    }

    // Step 7: å„²å­˜
    // Qdrant
    payload := map[string]interface{}{
        "content":    post.Content,
        "cluster_id": clusterID,
        "score":      score,
        "risk_score": riskScore,
    }
    if err := p.qdrantStore.Upsert(ctx, post.ID, toFloat32(embedding), payload); err != nil {
        return fmt.Errorf("qdrant upsert failed: %w", err)
    }

    // PostgreSQL
    postTag := &storage.PostTag{
        PostID:    post.ID,
        ClusterID: clusterID,
        RiskScore: riskScore,
    }
    if tagResult != nil {
        postTag.SoftTags = tagResult.SoftTags
        postTag.Sentiment = tagResult.Sentiment
    }
    if err := p.postgresStore.SavePostTag(ctx, postTag); err != nil {
        return fmt.Errorf("postgres save failed: %w", err)
    }

    log.Printf("Processed post %s â†’ cluster %s (score: %.2f, risk: %d)",
        post.ID, clusterID, score, riskScore)

    return nil
}

func (p *Processor) rulesFilter(post *Post) bool {
    // æ’é™¤æŠ½ç
    keywords := []string{"æŠ½ç", "giveaway", "ç•™è¨€+åˆ†äº«", "tagå¥½å‹"}
    for _, kw := range keywords {
        if strings.Contains(post.Content, kw) {
            return false
        }
    }

    // æ’é™¤å¤ªçŸ­
    if len(post.Content) < 20 {
        return false
    }

    return true
}

func (p *Processor) calculateRiskScore(post *Post) int {
    score := 50

    // å…§å®¹é•·åº¦
    if len(post.Content) > 50 {
        score += 10
    }
    if len(post.Content) > 100 {
        score += 10
    }

    // äº’å‹•æ•¸æ“š
    if post.Likes > 50 {
        score += 10
    }
    if post.Comments > 10 {
        score += 10
    }

    // æœ‰æè¿°è©
    descriptive := []string{"æ¨è–¦", "è¶…å¥½ç”¨", "é›·", "å›è³¼", "å¿…è²·"}
    for _, d := range descriptive {
        if strings.Contains(post.Content, d) {
            score += 10
            break
        }
    }

    if score > 100 {
        score = 100
    }
    return score
}

func toFloat32(f64 []float64) []float32 {
    f32 := make([]float32, len(f64))
    for i, v := range f64 {
        f32[i] = float32(v)
    }
    return f32
}
```

**é©—æ”¶æ¨™æº–**:
```
â˜ å–®ç¯‡è™•ç†å®Œæ•´æµç¨‹ < 300ms
â˜ Rules Filter æ­£ç¢ºæ’é™¤æŠ½çæ–‡
â˜ Risk Score è¨ˆç®—æ­£ç¢º
â˜ é«˜åƒ¹å€¼è²¼æ–‡æœ‰ LLM Tags
â˜ ä½åƒ¹å€¼è²¼æ–‡ç„¡ LLM Tagsï¼ˆç¯€çœæˆæœ¬ï¼‰
â˜ æ¯”å°å¤±æ•—çš„é€²å…¥ Pending Pool
```

---

### 4.2 Step 7: Batch Clusterer (Day 10)

**æª”æ¡ˆ**: `cmd/clusterer/main.go`

```go
package main

import (
    "context"
    "log"
    "time"

    "kolr-dynamic-tagging/internal/clustering"
    "kolr-dynamic-tagging/internal/ml"
    "kolr-dynamic-tagging/internal/storage"
)

type BatchClusterer struct {
    pendingPool   *storage.RedisQueue
    clusterClient *ml.ClusteringClient
    centroidMgr   *clustering.CentroidManager
    threshold     int // è§¸ç™¼é–¾å€¼
}

func (bc *BatchClusterer) Run(ctx context.Context) {
    ticker := time.NewTicker(5 * time.Minute) // æ¯ 5 åˆ†é˜æª¢æŸ¥
    defer ticker.Stop()

    for {
        select {
        case <-ctx.Done():
            return
        case <-ticker.C:
            bc.checkAndProcess(ctx)
        }
    }
}

func (bc *BatchClusterer) checkAndProcess(ctx context.Context) {
    count, err := bc.pendingPool.Len(ctx)
    if err != nil {
        log.Printf("Error getting pending pool length: %v", err)
        return
    }

    if count < int64(bc.threshold) {
        log.Printf("Pending pool size: %d (threshold: %d), skipping", count, bc.threshold)
        return
    }

    log.Printf("Pending pool reached threshold (%d), triggering HDBSCAN", count)

    // å–å‡ºæ‰€æœ‰ pending embeddings
    items, err := bc.pendingPool.PopAll(ctx)
    if err != nil {
        log.Printf("Error popping pending pool: %v", err)
        return
    }

    // å‘¼å« HDBSCAN
    result, err := bc.clusterClient.RunClustering(ctx, items.Embeddings, items.Texts)
    if err != nil {
        log.Printf("HDBSCAN failed: %v", err)
        // æ”¾å› pending pool
        bc.pendingPool.PushBatch(ctx, items)
        return
    }

    // è™•ç†çµæœ
    log.Printf("HDBSCAN found %d clusters, %d noise", len(result.Clusters), result.NoiseCount)

    for _, cluster := range result.Clusters {
        // æª¢æŸ¥æ˜¯å¦èˆ‡ç¾æœ‰ Cluster é‡ç–Š
        existingID, score, _ := bc.centroidMgr.FindNearest(ctx, cluster.Centroid)

        if existingID != "" && score > 0.85 {
            // é‡ç–Šï¼Œæ›´æ–°ç¾æœ‰ Cluster
            log.Printf("Cluster '%s' overlaps with existing '%s' (score: %.2f), merging",
                cluster.Name, existingID, score)
            bc.centroidMgr.Update(ctx, existingID, cluster.Centroid)
        } else {
            // æ–° Cluster
            newID := generateClusterID()
            log.Printf("New cluster discovered: %s (%s), size: %d",
                newID, cluster.Name, cluster.Size)
            bc.centroidMgr.Add(ctx, newID, cluster.Centroid)
            // TODO: å„²å­˜ Cluster è³‡è¨Šåˆ° PostgreSQL
        }
    }
}

func generateClusterID() string {
    return fmt.Sprintf("cluster_%d", time.Now().UnixNano())
}
```

**é©—æ”¶æ¨™æº–**:
```
â˜ å®šæœŸæª¢æŸ¥ Pending Pool
â˜ é”åˆ°é–¾å€¼è‡ªå‹•è§¸ç™¼ HDBSCAN
â˜ æ–° Cluster å­˜å…¥ Redis
â˜ é‡ç–Š Cluster æ­£ç¢ºåˆä½µ
â˜ å¾ŒçºŒè²¼æ–‡å¯å³æ™‚æ­¸é¡
```

---

## 5. Phase 3: API + é©—è­‰ (Day 11-14)

### 5.1 Step 8: Search API (Day 11)

**æª”æ¡ˆ**: `cmd/api/main.go`

```go
package main

import (
    "net/http"

    "github.com/gin-gonic/gin"
    "kolr-dynamic-tagging/internal/ml"
    "kolr-dynamic-tagging/internal/storage"
)

type API struct {
    embedClient   *ml.EmbeddingClient
    qdrantStore   *storage.QdrantStore
    postgresStore *storage.PostgresStore
}

type SearchRequest struct {
    Query string `json:"query" binding:"required"`
    Limit int    `json:"limit"`
}

type SearchResult struct {
    PostID    string   `json:"post_id"`
    Content   string   `json:"content"`
    Score     float32  `json:"score"`
    ClusterID string   `json:"cluster_id"`
    SoftTags  []string `json:"soft_tags"`
}

func (a *API) Search(c *gin.Context) {
    var req SearchRequest
    if err := c.ShouldBindJSON(&req); err != nil {
        c.JSON(http.StatusBadRequest, gin.H{"error": err.Error()})
        return
    }

    if req.Limit == 0 {
        req.Limit = 10
    }

    // 1. Query Embedding
    embedding, err := a.embedClient.Embed(c.Request.Context(), req.Query)
    if err != nil {
        c.JSON(http.StatusInternalServerError, gin.H{"error": "embedding failed"})
        return
    }

    // 2. Qdrant Search
    results, err := a.qdrantStore.Search(c.Request.Context(), toFloat32(embedding), uint64(req.Limit))
    if err != nil {
        c.JSON(http.StatusInternalServerError, gin.H{"error": "search failed"})
        return
    }

    // 3. çµ„è£çµæœ
    var searchResults []SearchResult
    for _, r := range results {
        sr := SearchResult{
            PostID:    r.Id.GetStr(),
            Score:     r.Score,
            Content:   r.Payload["content"].GetStringValue(),
            ClusterID: r.Payload["cluster_id"].GetStringValue(),
        }
        searchResults = append(searchResults, sr)
    }

    c.JSON(http.StatusOK, gin.H{
        "query":   req.Query,
        "results": searchResults,
    })
}

func (a *API) GetClusters(c *gin.Context) {
    clusters, err := a.postgresStore.GetAllClusters(c.Request.Context())
    if err != nil {
        c.JSON(http.StatusInternalServerError, gin.H{"error": err.Error()})
        return
    }
    c.JSON(http.StatusOK, clusters)
}

func (a *API) GetClusterPosts(c *gin.Context) {
    clusterID := c.Param("id")
    limit := 50

    posts, err := a.postgresStore.GetPostsByCluster(c.Request.Context(), clusterID, limit)
    if err != nil {
        c.JSON(http.StatusInternalServerError, gin.H{"error": err.Error()})
        return
    }
    c.JSON(http.StatusOK, posts)
}

func main() {
    r := gin.Default()

    api := &API{
        // åˆå§‹åŒ–...
    }

    r.POST("/search", api.Search)
    r.GET("/clusters", api.GetClusters)
    r.GET("/clusters/:id/posts", api.GetClusterPosts)

    r.Run(":8080")
}
```

**API è¦æ ¼**:
```
POST /search
Request:  {"query": "æŒå¦åº•å¦æ¨è–¦", "limit": 10}
Response: {"query": "...", "results": [{post_id, content, score, cluster_id}, ...]}

GET /clusters
Response: [{id, name, post_count, keywords}, ...]

GET /clusters/:id/posts
Response: [{post_id, content, soft_tags, sentiment}, ...]
```

**é©—æ”¶æ¨™æº–**:
```
â˜ POST /search å»¶é² < 100ms
â˜ æœå°‹çµæœç›¸é—œæ€§äººå·¥è©•ä¼° > 80%
â˜ GET /clusters åˆ—å‡ºæ‰€æœ‰ Cluster
â˜ GET /clusters/:id/posts æ­£ç¢ºå›å‚³
```

---

### 5.2 Step 9-10: æ¸¬è©¦èˆ‡é©—è­‰ (Day 12-14)

**æ¸¬è©¦è…³æœ¬**: `scripts/run_showcase.sh`

```bash
#!/bin/bash

echo "=== Dynamic Tagging Show Case ==="
echo ""

# Step 1: æ¸…ç©ºè³‡æ–™
echo "[1/7] æ¸…ç©ºæ‰€æœ‰è³‡æ–™..."
redis-cli FLUSHALL
curl -X DELETE "http://localhost:6333/collections/posts"
psql -c "TRUNCATE post_tags, clusters, cluster_history"

# Step 2: å†·å•Ÿå‹•æ¸¬è©¦
echo "[2/7] å†·å•Ÿå‹•æ¸¬è©¦ - è™•ç†å‰ 5000 ç¯‡..."
go run cmd/processor/main.go --input testdata/beauty_posts_50k.json --limit 5000

echo "ç­‰å¾… HDBSCAN è§¸ç™¼..."
sleep 30

# Step 3: é©—è­‰ Cluster ç”¢ç”Ÿ
echo "[3/7] é©—è­‰ Cluster ç”¢ç”Ÿ..."
CLUSTER_COUNT=$(redis-cli HLEN cluster:centroids)
echo "Cluster æ•¸é‡: $CLUSTER_COUNT"

# Step 4: æ­£å¸¸è™•ç†æ¸¬è©¦
echo "[4/7] è™•ç†å‰©é¤˜è²¼æ–‡..."
go run cmd/processor/main.go --input testdata/beauty_posts_50k.json --skip 5000

# Step 5: æœå°‹æ¸¬è©¦
echo "[5/7] æœå°‹æ•ˆæœæ¸¬è©¦..."
curl -X POST http://localhost:8080/search \
  -H "Content-Type: application/json" \
  -d '{"query": "æŒå¦åº•å¦æ¨è–¦", "limit": 10}'

echo ""

# Step 6: çµ±è¨ˆå ±å‘Š
echo "[6/7] ç”Ÿæˆçµ±è¨ˆå ±å‘Š..."
go run scripts/evaluate.go

# Step 7: å®Œæˆ
echo "[7/7] Show Case å®Œæˆï¼"
```

**è©•ä¼°è…³æœ¬**: `scripts/evaluate.go`

```go
package main

import (
    "context"
    "fmt"
    "log"
)

func main() {
    ctx := context.Background()

    // é€£æ¥è³‡æ–™åº«...

    // çµ±è¨ˆ
    stats := collectStats(ctx)

    fmt.Println("=== PoC æˆæœå ±å‘Š ===")
    fmt.Println("")
    fmt.Printf("ğŸ“Š æ•¸æ“šè¦æ¨¡\n")
    fmt.Printf("â”œâ”€ è™•ç†è²¼æ–‡: %d ç¯‡\n", stats.TotalPosts)
    fmt.Printf("â”œâ”€ ç¸½è€—æ™‚: %s\n", stats.Duration)
    fmt.Printf("â””â”€ ç¸½æˆæœ¬: $%.2f\n", stats.Cost)
    fmt.Println("")
    fmt.Printf("ğŸ“ˆ Cluster çµ±è¨ˆ\n")
    fmt.Printf("â”œâ”€ Cluster æ•¸: %d å€‹\n", stats.ClusterCount)
    fmt.Printf("â”œâ”€ æœ€å¤§ Cluster: %s (%d ç¯‡)\n", stats.LargestCluster, stats.LargestSize)
    fmt.Printf("â”œâ”€ å™ªé»æ¯”ä¾‹: %.1f%%\n", stats.NoiseRate*100)
    fmt.Printf("â””â”€ å³æ™‚æ­¸é¡ç‡: %.1f%%\n", stats.AssignRate*100)
    fmt.Println("")
    fmt.Printf("âœ… æŒ‡æ¨™é”æˆ\n")
    fmt.Printf("â”œâ”€ æ¨™ç±¤ç›¸é—œæ€§: %.0f%% (ç›®æ¨™ â‰¥85%%)\n", stats.Relevance*100)
    fmt.Printf("â”œâ”€ è¦†è“‹ç‡: %.0f%% (ç›®æ¨™ â‰¥90%%)\n", stats.Coverage*100)
    fmt.Printf("â””â”€ èšé¡ä¸€è‡´æ€§: %.0f%% (ç›®æ¨™ â‰¥80%%)\n", stats.Consistency*100)
}
```

---

## 6. å°ˆæ¡ˆçµæ§‹ç¸½è¦½

```
kolr-dynamic-tagging/
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ Makefile
â”œâ”€â”€ go.mod
â”œâ”€â”€ go.sum
â”œâ”€â”€ README.md
â”‚
â”œâ”€â”€ cmd/
â”‚   â”œâ”€â”€ processor/              # ä¸»è™•ç†æµç¨‹
â”‚   â”‚   â””â”€â”€ main.go
â”‚   â”œâ”€â”€ clusterer/              # æ‰¹æ¬¡èšé¡
â”‚   â”‚   â””â”€â”€ main.go
â”‚   â””â”€â”€ api/                    # REST API
â”‚       â””â”€â”€ main.go
â”‚
â”œâ”€â”€ internal/
â”‚   â”œâ”€â”€ filter/
â”‚   â”‚   â””â”€â”€ rules.go            # L1 Rules Filter
â”‚   â”œâ”€â”€ scoring/
â”‚   â”‚   â””â”€â”€ risk_score.go       # L2 Risk Score
â”‚   â”œâ”€â”€ clustering/
â”‚   â”‚   â””â”€â”€ centroid_manager.go # Centroid ç®¡ç†
â”‚   â”œâ”€â”€ tagging/
â”‚   â”‚   â””â”€â”€ soft_tagger.go      # LLM Tagging
â”‚   â”œâ”€â”€ storage/
â”‚   â”‚   â”œâ”€â”€ qdrant.go           # å‘é‡å„²å­˜
â”‚   â”‚   â”œâ”€â”€ postgres.go         # é—œè¯å¼å„²å­˜
â”‚   â”‚   â””â”€â”€ redis.go            # å¿«å– + Queue
â”‚   â””â”€â”€ ml/
â”‚       â”œâ”€â”€ client.go           # gRPC Client
â”‚       â””â”€â”€ embedding_client.go
â”‚
â”œâ”€â”€ proto/
â”‚   â””â”€â”€ ml.proto                # gRPC å®šç¾©
â”‚
â”œâ”€â”€ ml_service/                 # Python ML æœå‹™
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â”œâ”€â”€ requirements.txt
â”‚   â”œâ”€â”€ embedding_server.py
â”‚   â””â”€â”€ clustering_server.py
â”‚
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ init.sql                # è³‡æ–™åº«åˆå§‹åŒ–
â”‚   â”œâ”€â”€ export_posts.sql        # åŒ¯å‡ºæ¸¬è©¦è³‡æ–™
â”‚   â”œâ”€â”€ run_showcase.sh         # Show Case è…³æœ¬
â”‚   â””â”€â”€ evaluate.go             # è©•ä¼°è…³æœ¬
â”‚
â””â”€â”€ testdata/
    â””â”€â”€ beauty_posts_50k.json   # æ¸¬è©¦è³‡æ–™
```

---

## 7. Checklist ç¸½è¦½

```
Phase 0: ç’°å¢ƒæº–å‚™ (Day 1-2)
â˜ Docker Compose ç’°å¢ƒ
â˜ Python ML ç’°å¢ƒ
â˜ Go é–‹ç™¼ç’°å¢ƒ
â˜ æ¸¬è©¦è³‡æ–™æº–å‚™

Phase 1: æ ¸å¿ƒå…ƒä»¶ (Day 3-7)
â˜ Step 1: Embedding Service (Day 3)
â˜ Step 2: Centroid Manager (Day 4)
â˜ Step 3: HDBSCAN Service (Day 5)
â˜ Step 4: LLM Tagger (Day 6)
â˜ Step 5: Storage Layer (Day 7)

Phase 2: æµç¨‹æ•´åˆ (Day 8-10)
â˜ Step 6: Post Processor (Day 8-9)
â˜ Step 7: Batch Clusterer (Day 10)

Phase 3: API + é©—è­‰ (Day 11-14)
â˜ Step 8: Search API (Day 11)
â˜ Step 9: å†·å•Ÿå‹•æ¸¬è©¦ (Day 12)
â˜ Step 10: Show Case æ¸¬è©¦ (Day 13-14)

æœ€çµ‚é©—æ”¶
â˜ æ¨™ç±¤ç›¸é—œæ€§ â‰¥ 85%
â˜ è¦†è“‹ç‡ â‰¥ 90%
â˜ èšé¡ä¸€è‡´æ€§ â‰¥ 80%
â˜ è™•ç†å»¶é² < 300ms
â˜ æˆæœ¬ < $5
â˜ Demo å®Œæˆ
```

---

## Changelog

| Version | Date | Author | Changes |
|---------|------|--------|---------|
| v1.0 | 2026-02-03 | Kolr Engineering | Initial development plan |
